import os
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from wordcloud import WordCloud
import pandas as pd
import numpy as np
import re
import json
from collections import Counter
import matplotlib.pyplot as plt
import io
import requests
from datetime import datetime
import time

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ç”¨æˆ·ä¹‹å£°å›éŸ³å£ (Echo) Pro",
    page_icon="ğŸ”Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 0.5rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 1rem;
        text-align: center;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        transition: transform 0.3s ease;
    }
    .metric-card:hover {
        transform: translateY(-5px);
    }
    .insight-box {
        background: linear-gradient(135deg, #e3f2fd 0%, #f3e5f5 100%);
        padding: 1.5rem;
        border-radius: 1rem;
        border-left: 4px solid #1f77b4;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .positive-insight {
        background: linear-gradient(135deg, #e8f5e8 0%, #f1f8e9 100%);
        border-left: 4px solid #4caf50;
    }
    .negative-insight {
        background: linear-gradient(135deg, #ffebee 0%, #fce4ec 100%);
        border-left: 4px solid #f44336;
    }
    .feature-card {
        background: white;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# (ä½ éœ€è¦ä¿ç•™æ–‡ä»¶é¡¶éƒ¨çš„æ‰€æœ‰ import è¯­å¥)
# (è¯·ç”¨ä¸‹é¢çš„æ–°ç±»ï¼Œå®Œæ•´æ›¿æ¢æ‰ä½ åŸæ¥çš„ AIEnhancedEchoAnalyzer ç±»)

class LLMEchoAnalyzer:
    def __init__(self, api_key):
        self.api_key = api_key
        # æ™ºè°±AIçš„APIåœ°å€
        self.url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
    # (ä½ éœ€è¦ä¿ç•™æ–‡ä»¶é¡¶éƒ¨çš„æ‰€æœ‰ import è¯­å¥)
# (è¯·ç”¨ä¸‹é¢çš„æ–°ç±»ï¼Œå®Œæ•´æ›¿æ¢æ‰ä½ åŸæ¥çš„ AIEnhancedEchoAnalyzer ç±»)

class LLMEchoAnalyzer:
    def __init__(self, api_key):
        self.api_key = api_key
        self.url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"

    def clean_text(self, text):
        """æ¸…ç†å’Œé¢„å¤„ç†æ–‡æœ¬æ•°æ®"""
        text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\s\.\!\?\,\;\:\"\'()ï¼ˆï¼‰ã€‚ï¼ï¼Ÿï¼Œï¼›ï¼š""'']', '', text)
        text = re.sub(r'\s+', ' ', text.strip())
        comments = [line.strip() for line in text.split('\n') if line.strip() and len(line) > 3]
        return comments

    def analyze(self, comments):
        """ä½¿ç”¨LLM APIè¿›è¡Œå…¨é¢ã€æ™ºèƒ½çš„åˆ†æï¼Œå¹¶è¿”å›è¯¦ç»†çš„é€æ¡ç»“æœ"""
        if not self.api_key:
            st.error("API Keyæœªè®¾ç½®ï¼Œè¯·åœ¨Streamlit Secretsä¸­é…ç½® ZHIPU_API_KEYã€‚")
            return None

        headers = {"Content-Type": "application/json", "Authorization": f"Bearer {self.api_key}"}
        # å°†è¯„è®ºåˆ—è¡¨æ ¼å¼åŒ–ï¼Œæ¯æ¡è¯„è®ºå‰åŠ ä¸Šç¼–å·ï¼Œæ–¹ä¾¿AIå¤„ç†
        formatted_comments = "\n".join([f"{i+1}. {comment}" for i, comment in enumerate(comments)])

        # å…¨æ–°çš„ã€è¦æ±‚æ›´è¯¦ç»†çš„Prompt
        prompt = f"""
        ä½ æ˜¯ä¸€ä½é¡¶çº§çš„APPç”¨æˆ·åé¦ˆåˆ†æä¸“å®¶ã€‚è¯·æ·±å…¥åˆ†æä»¥ä¸‹ç”¨æˆ·è¯„è®ºåˆ—è¡¨ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¿”å›ç»“æœã€‚

        ç”¨æˆ·è¯„è®ºåˆ—è¡¨:
        ---
        {formatted_comments}
        ---

        è¯·å®Œæˆä»¥ä¸‹ä¸¤é¡¹ä»»åŠ¡:

        ä»»åŠ¡1: ç”Ÿæˆè¯¦ç»†åˆ†ææ•°æ® (detailed_data)
        - éå†æ¯ä¸€æ¡è¯„è®ºã€‚
        - å¯¹æ¯ä¸€æ¡è¯„è®ºï¼Œåˆ†æå‡ºå…¶'æƒ…æ„Ÿå€¾å‘(sentiment)' ('positive', 'negative', 'neutral') å’Œ 'æ ¸å¿ƒæ„å›¾(intent)' ('bugåé¦ˆ', 'åŠŸèƒ½å»ºè®®', 'ä½“éªŒèµæ‰¬', 'ä½“éªŒæŠ±æ€¨', 'å’¨è¯¢')ã€‚
        - å°†æ¯æ¡è¯„è®ºçš„åˆ†æç»“æœä½œä¸ºä¸€ä¸ªJSONå¯¹è±¡æ”¾å…¥åˆ—è¡¨ä¸­ã€‚

        ä»»åŠ¡2: ç”Ÿæˆæ‘˜è¦æ•°æ® (summary_data)
        - æ ¹æ®è¯¦ç»†åˆ†æç»“æœï¼Œç»Ÿè®¡æƒ…æ„Ÿå’Œæ„å›¾çš„æ±‡æ€»æ•°é‡ã€‚
        - æå–æœ€èƒ½ä»£è¡¨ç”¨æˆ·å…³æ³¨ç„¦ç‚¹çš„15ä¸ªæ ¸å¿ƒå…³é”®è¯ã€‚
        - æ€»ç»“å‡º3æ¡æœ€å…·ä»£è¡¨æ€§çš„æ­£é¢å’Œè´Ÿé¢åé¦ˆè§‚ç‚¹ã€‚

        è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å«ä»»ä½•æ— å…³çš„æ–‡å­—ã€è§£é‡Šæˆ–ä»£ç æ ‡è®°:
        {{
          "detailed_data": [
            {{
              "comment": "<åŸå§‹è¯„è®ºå†…å®¹>",
              "sentiment": "<positive/negative/neutral>",
              "intent": "<bugåé¦ˆ/åŠŸèƒ½å»ºè®®/ç­‰>"
            }},
            ...
          ],
          "summary_data": {{
            "sentiment_analysis": {{ "positive": <integer>, "negative": <integer>, "neutral": <integer> }},
            "intent_classification": {{ "bugåé¦ˆ": <integer>, "åŠŸèƒ½å»ºè®®": <integer>, "ä½“éªŒèµæ‰¬": <integer>, "ä½“éªŒæŠ±æ€¨": <integer>, "å’¨è¯¢": <integer> }},
            "keyword_extraction": [ {{"keyword": "<string>", "count": <integer>}}, ... ],
            "summary": {{
              "positive_highlights": ["<string>", "<string>", "<string>"],
              "negative_highlights": ["<string>", "<string>", "<string>"]
            }}
          }}
        }}
        """
        payload = {"model": "glm-4", "messages": [{"role": "user", "content": prompt}], "response_format": {"type": "json_object"}}

        try:
            response = requests.post(self.url, headers=headers, json=payload, timeout=180)
            response.raise_for_status()
            analysis_str = response.json()['choices'][0]['message']['content']
            return json.loads(analysis_str)
        except requests.exceptions.RequestException as e:
            st.error(f"è°ƒç”¨AIæ¨¡å‹APIå¤±è´¥: {e}")
            return None
        except (json.JSONDecodeError, KeyError, IndexError) as e:
            st.error(f"è§£æAIæ¨¡å‹è¿”å›æ•°æ®å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚é”™è¯¯: {e}")
            st.code(response.text, language="text")
            return None

def create_enhanced_visualizations(results):
    """åˆ›å»ºå¢å¼ºç‰ˆå¯è§†åŒ–å›¾è¡¨"""
    
    # 1. æƒ…æ„Ÿåˆ†å¸ƒå¸¦ç½®ä¿¡åº¦çš„é¥¼å›¾
    sentiment_values = list(results['sentiment_results'].values())
    sentiment_labels = ['æ­£é¢è¯„ä»·', 'è´Ÿé¢è¯„ä»·', 'ä¸­æ€§è¯„ä»·']
    
    # ç¡®ä¿æœ‰æœ‰æ•ˆæ•°æ®
    if sum(sentiment_values) == 0:
        sentiment_values = [1, 0, 0]  # é»˜è®¤å€¼é¿å…ç©ºå›¾è¡¨
    
    sentiment_fig = go.Figure(data=[go.Pie(
        labels=sentiment_labels,
        values=sentiment_values,
        hole=0.4,
        marker_colors=['#28a745', '#dc3545', '#ffc107'],
        textinfo='label+percent+value',
        textposition='auto',
        hovertemplate='<b>%{label}</b><br>æ•°é‡: %{value}<br>å æ¯”: %{percent}<extra></extra>'
    )])
    
    sentiment_fig.update_layout(
        title={
            'text': 'ç”¨æˆ·æƒ…æ„Ÿåˆ†å¸ƒåˆ†æ',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 18, 'family': 'Arial'}
        },
        font=dict(size=12),
        showlegend=True,
        legend=dict(orientation="v", yanchor="middle", y=0.5, xanchor="left", x=1.01)
    )
    
    # 2. æ„å›¾åˆ†ç±»æ¡å½¢å›¾ï¼ˆæ›¿æ¢ç€‘å¸ƒå›¾é¿å…å…¼å®¹æ€§é—®é¢˜ï¼‰
    intent_data = {k: v for k, v in results['intent_results'].items() if v > 0}
    
    # ç¡®ä¿æœ‰æœ‰æ•ˆæ•°æ®
    if not intent_data:
        intent_data = {'å…¶ä»–': 1}  # é»˜è®¤å€¼é¿å…ç©ºå›¾è¡¨
    
    # ä½¿ç”¨æ¡å½¢å›¾æ›¿ä»£ç€‘å¸ƒå›¾
    intent_fig = go.Figure(data=[go.Bar(
        x=list(intent_data.keys()),
        y=list(intent_data.values()),
        marker_color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'][:len(intent_data)],
        text=[f"{v}æ¡" for v in intent_data.values()],
        textposition='auto'
    )])
    
    intent_fig.update_layout(
        title={
            'text': 'ç”¨æˆ·åé¦ˆæ„å›¾åˆ†ç±»ç»Ÿè®¡',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 18, 'family': 'Arial'}
        },
        xaxis_title="åé¦ˆç±»å‹",
        yaxis_title="è¯„è®ºæ•°é‡",
        showlegend=False,
        xaxis=dict(tickangle=45)  # å€¾æ–œæ ‡ç­¾é¿å…é‡å 
    )
    
    return sentiment_fig, intent_fig

def main():
    # ä¸»æ ‡é¢˜
    st.markdown('<div class="main-header">ğŸ”Š ç”¨æˆ·ä¹‹å£°å›éŸ³å£ (Echo) Pro</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">ğŸ¤– AIé©±åŠ¨çš„ç”¨æˆ·åé¦ˆæ™ºèƒ½åˆ†æå¹³å°ï¼Œè®©æ¯ä¸ªå£°éŸ³éƒ½è¢«å¬è§ã€è¢«ç†è§£ã€è¢«åˆ†æ</div>', unsafe_allow_html=True)
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.markdown("### ğŸš€ Echo Pro ç‰¹è‰²åŠŸèƒ½")
        
        features = [
            {"icon": "ğŸ¯", "title": "é«˜ç²¾åº¦æƒ…æ„Ÿåˆ†æ", "desc": "æ™ºèƒ½è¯†åˆ«ç”¨æˆ·æƒ…æ„Ÿå€¾å‘"},
            {"icon": "ğŸ”", "title": "æ™ºèƒ½å…³é”®è¯æå–", "desc": "è‡ªåŠ¨å‘ç°ç”¨æˆ·å…³æ³¨ç„¦ç‚¹"},
            {"icon": "ğŸ“‹", "title": "æ„å›¾æ™ºèƒ½åˆ†ç±»", "desc": "ç²¾å‡†è¯†åˆ«ç”¨æˆ·åé¦ˆç±»å‹"},
            {"icon": "ğŸ“Š", "title": "å¯è§†åŒ–åˆ†ææŠ¥å‘Š", "desc": "ç›´è§‚å±•ç¤ºåˆ†æç»“æœ"},
            {"icon": "ğŸ’¡", "title": "AIæ™ºèƒ½æ´å¯Ÿ", "desc": "ç”Ÿæˆæ”¹è¿›å»ºè®®å’Œä¼˜å…ˆçº§"},
            {"icon": "ğŸ“", "title": "ä¸€é”®å¯¼å‡ºæŠ¥å‘Š", "desc": "æ”¯æŒå¤šæ ¼å¼æ•°æ®å¯¼å‡º"}
        ]
        
        for feature in features:
            st.markdown(f"""
            <div class="feature-card">
                <strong>{feature['icon']} {feature['title']}</strong><br>
                <small>{feature['desc']}</small>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("---")
        st.markdown("### âš™ï¸ åˆ†æè®¾ç½®")
        
        # åˆ†æå‚æ•°è®¾ç½®
        confidence_threshold = st.slider("æƒ…æ„Ÿåˆ†æç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, 0.6, 0.1)
        keyword_limit = st.slider("å…³é”®è¯æå–æ•°é‡", 10, 50, 25, 5)
        
        st.markdown("### ğŸ“ˆ ä½¿ç”¨ç»Ÿè®¡")
        if 'analysis_count' not in st.session_state:
            st.session_state.analysis_count = 0
        st.metric("æœ¬æ¬¡ä¼šè¯åˆ†ææ¬¡æ•°", st.session_state.analysis_count)

    # åˆå§‹åŒ–å¢å¼ºåˆ†æå™¨
    # --- â†“â†“â†“ ç²˜è´´ä¸‹é¢çš„æ–°ä»£ç  â†“â†“â†“ ---
# åˆå§‹åŒ–æ–°çš„LLMåˆ†æå™¨ï¼Œå®ƒä¼šè‡ªåŠ¨ä»st.secretsè¯»å–API_KEY
    if 'analyzer' not in st.session_state:
        api_key = st.secrets.get("ZHIPU_API_KEY")
        st.session_state.analyzer = LLMEchoAnalyzer(api_key=api_key)

    # æ•°æ®è¾“å…¥æ¨¡å—
    st.markdown("## ğŸ“¥ æ™ºèƒ½æ•°æ®è¾“å…¥æ¨¡å—")
    
    # è¾“å…¥æ–¹å¼é€‰æ‹©
    input_method = st.radio(
        "é€‰æ‹©è¾“å…¥æ–¹å¼ï¼š",
        ["æ–‡æœ¬ç²˜è´´", "æ–‡ä»¶ä¸Šä¼ ", "ç¤ºä¾‹æ•°æ®"],
        horizontal=True
    )
    
    user_input = ""
    
    if input_method == "æ–‡æœ¬ç²˜è´´":
        col1, col2 = st.columns([3, 1])
        with col1:
            user_input = st.text_area(
                "è¯·ç²˜è´´ç”¨æˆ·è¯„è®ºæ–‡æœ¬ï¼ˆæ¯è¡Œä¸€æ¡è¯„è®ºï¼‰ï¼š",
                height=250,
                placeholder="åœ¨æ­¤ç²˜è´´ä»App Storeã€Google Playã€ç¤¾äº¤åª’ä½“ç­‰å¹³å°æ”¶é›†çš„ç”¨æˆ·è¯„è®º...\n\nç¤ºä¾‹æ ¼å¼ï¼š\nè¿™ä¸ªAPPçœŸçš„å¾ˆå¥½ç”¨ï¼Œç•Œé¢è®¾è®¡å¾ˆç¾è§‚ï¼\næœ€è¿‘æ€»æ˜¯é—ªé€€ï¼Œå¸Œæœ›èƒ½ä¿®å¤ä¸€ä¸‹\nåŠŸèƒ½æŒºå…¨çš„ï¼Œå°±æ˜¯æœ‰ç‚¹å¡é¡¿"
            )
        
        with col2:
            st.markdown("### ğŸ“Š è¾“å…¥ç»Ÿè®¡")
            if user_input:
                lines = len([line for line in user_input.split('\n') if line.strip()])
                chars = len(user_input)
                words = len(user_input.split())
                st.metric("è¯„è®ºæ¡æ•°", lines)
                st.metric("å­—ç¬¦æ€»æ•°", chars)
                st.metric("è¯æ±‡æ•°é‡", words)
                
                # è¾“å…¥è´¨é‡è¯„ä¼°
                avg_length = chars / lines if lines > 0 else 0
                if avg_length > 20:
                    st.success("âœ… è¯„è®ºé•¿åº¦é€‚ä¸­")
                elif avg_length > 10:
                    st.warning("âš ï¸ è¯„è®ºåçŸ­")
                else:
                    st.error("âŒ è¯„è®ºè¿‡çŸ­")
    
    elif input_method == "ç¤ºä¾‹æ•°æ®":
        sample_data_options = {
            "ç”µå•†APPè¯„è®º": """è¿™æ¬¾è´­ç‰©APPç•Œé¢è®¾è®¡å¾ˆæ¼‚äº®ï¼Œæ“ä½œä¹Ÿå¾ˆæµç•…
å•†å“ç§ç±»ä¸°å¯Œï¼Œä»·æ ¼ä¹Ÿæ¯”è¾ƒä¼˜æƒ ï¼Œå¾ˆæ»¡æ„
æœ€è¿‘APPæ€»æ˜¯é—ªé€€ï¼Œç‰¹åˆ«æ˜¯åœ¨æ”¯ä»˜çš„æ—¶å€™ï¼Œå¾ˆå½±å“è´­ç‰©ä½“éªŒ
å¸Œæœ›èƒ½å¢åŠ å•†å“å¯¹æ¯”åŠŸèƒ½ï¼Œæ–¹ä¾¿é€‰æ‹©
å®¢æœå›å¤å¾ˆåŠæ—¶ï¼Œè§£å†³é—®é¢˜çš„æ•ˆç‡å¾ˆé«˜
ç‰©æµä¿¡æ¯æ›´æ–°ä¸åŠæ—¶ï¼Œä¸çŸ¥é“åŒ…è£¹åˆ°å“ªäº†
å»ºè®®ä¼˜åŒ–æœç´¢åŠŸèƒ½ï¼Œæœ‰æ—¶å€™æœä¸åˆ°æƒ³è¦çš„å•†å“
æ•´ä½“ä½“éªŒä¸é”™ï¼Œä¼šç»§ç»­ä½¿ç”¨å¹¶æ¨èç»™æœ‹å‹
ç»“è´¦é¡µé¢æœ‰bugï¼Œç‚¹å‡»æ”¯ä»˜æŒ‰é’®æ²¡æœ‰ååº”
å¸Œæœ›èƒ½æ”¯æŒæ›´å¤šæ”¯ä»˜æ–¹å¼ï¼Œæ¯”å¦‚æ•°å­—é’±åŒ…""",
            
            "ç¤¾äº¤åª’ä½“APPè¯„è®º": """ç•Œé¢ç®€æ´ç¾è§‚ï¼Œå¾ˆç¬¦åˆå¹´è½»äººçš„å®¡ç¾
å‘å¸ƒåŠŸèƒ½å¾ˆå®Œå–„ï¼Œæ”¯æŒå¤šç§æ ¼å¼çš„å†…å®¹
æœ€è¿‘æ›´æ–°åç»å¸¸å¡é¡¿ï¼Œå¸Œæœ›èƒ½ä¼˜åŒ–ä¸€ä¸‹æ€§èƒ½
å»ºè®®å¢åŠ å¤œé—´æ¨¡å¼ï¼Œé•¿æ—¶é—´ä½¿ç”¨çœ¼ç›ä¼šç´¯
ç§ä¿¡åŠŸèƒ½å¾ˆå¥½ç”¨ï¼Œå’Œæœ‹å‹èŠå¤©å¾ˆæ–¹ä¾¿
å¹¿å‘Šå¤ªå¤šäº†ï¼Œå½±å“ä½¿ç”¨ä½“éªŒ
å¸Œæœ›èƒ½å¢åŠ æ›´å¤šçš„æ»¤é•œå’Œè´´çº¸
ç”¨æˆ·éšç§ä¿æŠ¤åšå¾—ä¸é”™ï¼Œå¾ˆæœ‰å®‰å…¨æ„Ÿ
è§†é¢‘åŠ è½½é€Ÿåº¦æœ‰ç‚¹æ…¢ï¼Œç‰¹åˆ«æ˜¯åœ¨ç½‘ç»œä¸å¥½çš„æ—¶å€™
ç‚¹èµå’Œè¯„è®ºåŠŸèƒ½å“åº”åŠæ—¶ï¼Œäº’åŠ¨ä½“éªŒå¾ˆå¥½""",
            
            "å­¦ä¹ æ•™è‚²APPè¯„è®º": """è¯¾ç¨‹å†…å®¹è´¨é‡å¾ˆé«˜ï¼Œè€å¸ˆè®²è§£å¾ˆè¯¦ç»†
ç•Œé¢è®¾è®¡ç®€æ´ï¼ŒåŠŸèƒ½åˆ†å¸ƒåˆç†ï¼Œä½¿ç”¨æ–¹ä¾¿
è§†é¢‘æ’­æ”¾ç»å¸¸å¡é¡¿ï¼Œå½±å“å­¦ä¹ æ•ˆæœ
å¸Œæœ›èƒ½å¢åŠ ç¦»çº¿ä¸‹è½½åŠŸèƒ½ï¼Œæ–¹ä¾¿éšæ—¶å­¦ä¹ 
ç»ƒä¹ é¢˜ç›®è®¾è®¡å¾ˆå¥½ï¼Œæœ‰åŠ©äºå·©å›ºçŸ¥è¯†ç‚¹
å®¢æœæ€åº¦å¾ˆå¥½ï¼Œè§£ç­”é—®é¢˜å¾ˆè€å¿ƒ
å»ºè®®å¢åŠ å­¦ä¹ è¿›åº¦ç»Ÿè®¡åŠŸèƒ½
æ•´ä½“å­¦ä¹ ä½“éªŒä¸é”™ï¼Œç¡®å®æœ‰æå‡
APPå¯åŠ¨é€Ÿåº¦æœ‰ç‚¹æ…¢ï¼Œå¸Œæœ›èƒ½ä¼˜åŒ–
å¸Œæœ›èƒ½å¢åŠ æ›´å¤šäº’åŠ¨åŠŸèƒ½ï¼Œæé«˜å­¦ä¹ å…´è¶£"""
        }
        
        selected_sample = st.selectbox("é€‰æ‹©ç¤ºä¾‹æ•°æ®ï¼š", list(sample_data_options.keys()))
        user_input = sample_data_options[selected_sample]
        st.text_area("ç¤ºä¾‹æ•°æ®é¢„è§ˆï¼š", value=user_input, height=200, disabled=True)
    
    elif input_method == "æ–‡ä»¶ä¸Šä¼ ":
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ è¯„è®ºæ–‡ä»¶",
            type=['txt', 'csv'],
            help="æ”¯æŒ.txtå’Œ.csvæ ¼å¼æ–‡ä»¶ï¼Œæ¯è¡Œä¸€æ¡è¯„è®º"
        )
        if uploaded_file:
            try:
                content = uploaded_file.read().decode('utf-8')
                user_input = content
                st.success(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼å…±{len(content.split())}è¡Œå†…å®¹")
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")

    # åˆ†ææ§åˆ¶é¢æ¿
    st.markdown("---")
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        analyze_button = st.button("ğŸš€ å¼€å§‹AIæ™ºèƒ½åˆ†æ", type="primary", use_container_width=True)
    
    with col2:
        if st.button("ğŸ§¹ æ¸…ç©ºè¾“å…¥", use_container_width=True):
            st.rerun()
    
    with col3:
        if st.button("ğŸ“Š æŸ¥çœ‹å†å²", use_container_width=True):
            st.info("å†å²åˆ†æåŠŸèƒ½å¼€å‘ä¸­...")

    # æ‰§è¡Œåˆ†æ
    # --- â†“â†“â†“ ç²˜è´´ä¸‹é¢çš„æ–°ä»£ç  â†“â†“â†“ ---
    if analyze_button and user_input:
        with st.spinner('ğŸ¤– æ­£åœ¨è°ƒç”¨äº‘ç«¯AIå¤§æ¨¡å‹è¿›è¡Œæ·±åº¦åˆ†æï¼Œè¯·ç¨å€™...'):
            comments = st.session_state.analyzer.clean_text(user_input)
            
            if not comments:
                st.error("âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„è¯„è®ºå†…å®¹ã€‚")
                st.stop()
            
            llm_results = st.session_state.analyzer.analyze(comments)

            if llm_results and 'summary_data' in llm_results and 'detailed_data' in llm_results:
                st.session_state.analysis_count += 1
                summary = llm_results['summary_data']
                details = llm_results['detailed_data']

                # é‡æ–°æ„å»ºè¯¦ç»†åˆ†æåˆ—è¡¨ï¼Œæ¢å¤ä¸‹è½½ã€è¡¨æ ¼ç­‰åŠŸèƒ½
                sentiment_details_rebuilt = []
                intent_details_rebuilt = []
                for item in details:
                    # æ¨¡æ‹Ÿæ—§ç‰ˆæ•°æ®ç»“æ„ä»¥å…¼å®¹å‰ç«¯
                    sentiment_details_rebuilt.append({
                        'comment': item.get('comment', ''),
                        'sentiment': item.get('sentiment', 'neutral'),
                        'confidence': 0.95, # LLMç»“æœç»™ä¸€ä¸ªé«˜ç½®ä¿¡åº¦
                        'pos_score': 1 if item.get('sentiment') == 'positive' else 0,
                        'neg_score': 1 if item.get('sentiment') == 'negative' else 0
                    })
                    intent_details_rebuilt.append({
                        'comment': item.get('comment', ''),
                        'intent': item.get('intent', 'å…¶ä»–')
                    })
                
                # é‡æ–°å¡«å……æ‰€æœ‰å‰ç«¯éœ€è¦çš„æ•°æ®
                st.session_state.enhanced_results = {
                    'sentiment_results': summary.get('sentiment_analysis', {}),
                    'keywords': [(item['keyword'], item['count']) for item in summary.get('keyword_extraction', [])],
                    'intent_results': summary.get('intent_classification', {}),
                    'ai_insights': {
                        'positive_highlights': summary.get('summary', {}).get('positive_highlights', []),
                        'negative_highlights': summary.get('summary', {}).get('negative_highlights', []),
                        # é‡æ–°å¡«å……keyword_insightsä»¥ä¿®å¤KeyError
                        'keyword_insights': {
                            'tech_focus': any(kw['keyword'] in ['bug', 'å¡é¡¿', 'é—ªé€€'] for kw in summary.get('keyword_extraction', [])),
                            'ux_focus': any(kw['keyword'] in ['ç•Œé¢', 'è®¾è®¡', 'ä½“éªŒ'] for kw in summary.get('keyword_extraction', []))
                        },
                        'priority_issues': [],
                        'suggestions': []
                    },
                    'total_comments': len(comments), # ä½¿ç”¨æ¸…æ´—åçš„è¯„è®ºåˆ—è¡¨é•¿åº¦ï¼Œä¿è¯å‡†ç¡®
                    'avg_confidence': 0.95,
                    'analysis_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'sentiment_details': sentiment_details_rebuilt,
                    'intent_details': intent_details_rebuilt
                }
                st.success("ğŸ‰ AIæ·±åº¦åˆ†æå®Œæˆï¼")
            else:
                st.error("åˆ†æå¤±è´¥ï¼Œæœªèƒ½ä»AIæ¨¡å‹è·å–æœ‰æ•ˆæ•°æ®ã€‚")

    # æ˜¾ç¤ºå¢å¼ºåˆ†æç»“æœ
    if 'enhanced_results' in st.session_state:
        results = st.session_state.enhanced_results
        
        st.markdown("---")
        st.markdown("## ğŸ“Š AIæ™ºèƒ½åˆ†ææŠ¥å‘Š")
        
        # æ ¸å¿ƒæŒ‡æ ‡ä»ªè¡¨ç›˜
        st.markdown("### ğŸ¯ æ ¸å¿ƒæŒ‡æ ‡æ¦‚è§ˆ")
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.markdown(f"""
            <div class="metric-card">
                <h3>{results['total_comments']}</h3>
                <p>æ€»è¯„è®ºæ•°</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            positive_rate = round(results['sentiment_results']['positive'] / results['total_comments'] * 100, 1)
            st.markdown(f"""
            <div class="metric-card">
                <h3>{positive_rate}%</h3>
                <p>æ­£é¢è¯„ä»·ç‡</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            negative_rate = round(results['sentiment_results']['negative'] / results['total_comments'] * 100, 1)
            st.markdown(f"""
            <div class="metric-card">
                <h3>{negative_rate}%</h3>
                <p>è´Ÿé¢è¯„ä»·ç‡</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col4:
            confidence_score = round(results['avg_confidence'] * 100, 1)
            st.markdown(f"""
            <div class="metric-card">
                <h3>{confidence_score}%</h3>
                <p>åˆ†æç½®ä¿¡åº¦</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col5:
            intent_types = len([v for v in results['intent_results'].values() if v > 0])
            st.markdown(f"""
            <div class="metric-card">
                <h3>{intent_types}</h3>
                <p>åé¦ˆç±»å‹æ•°</p>
            </div>
            """, unsafe_allow_html=True)

        # å¢å¼ºç‰ˆå¯è§†åŒ–å›¾è¡¨
        st.markdown("### ğŸ“ˆ å¯è§†åŒ–åˆ†æå›¾è¡¨")
        
        sentiment_fig, intent_fig = create_enhanced_visualizations(results)
        
        col1, col2 = st.columns(2)
        with col1:
            st.plotly_chart(sentiment_fig, use_container_width=True)
        with col2:
            st.plotly_chart(intent_fig, use_container_width=True)
        
        # å…³é”®è¯åˆ†æ
        st.markdown("### â˜ï¸ æ™ºèƒ½å…³é”®è¯åˆ†æ")
        
        if results['keywords']:
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # ç”Ÿæˆè¯äº‘
                keywords_dict = dict(results['keywords'])
                if keywords_dict:
                    try:
                        plt.figure(figsize=(12, 6))
                        font_path = os.path.join('echo-project', 'fonts', 'font.otf')
                        wordcloud = WordCloud(
                            font_path=font_path,
                            width=1000, 
                            height=500,
                            background_color='white',
                            colormap='plasma',
                            max_words=30,
                            relative_scaling=0.5,
                            collocations=False,
                            prefer_horizontal=0.7
                        ).generate_from_frequencies(keywords_dict)
                        
                        plt.imshow(wordcloud, interpolation='bilinear')
                        plt.axis('off')
                        plt.title('ç”¨æˆ·å…³æ³¨çƒ­ç‚¹è¯äº‘å›¾', fontsize=16, pad=20)
                        
                        img_buffer = io.BytesIO()
                        plt.savefig(img_buffer, format='png', bbox_inches='tight', dpi=200, facecolor='white')
                        img_buffer.seek(0)
                        
                        st.image(img_buffer, use_column_width=True)
                        plt.close()
                    except Exception as e:
                        st.warning("âš ï¸ è¯äº‘å›¾ç”Ÿæˆå¤±è´¥ï¼Œå¯èƒ½æ˜¯å­—ä½“é—®é¢˜ã€‚æ˜¾ç¤ºå…³é”®è¯åˆ—è¡¨ä½œä¸ºæ›¿ä»£ã€‚")
                        # å¤‡ç”¨æ˜¾ç¤ºæ–¹æ¡ˆ
                        keyword_text = " | ".join([f"{word}({count})" for word, count in results['keywords'][:20]])
                        st.markdown(f"**å…³é”®è¯**: {keyword_text}")
            
            with col2:
                st.markdown("#### ğŸ”¥ é«˜é¢‘å…³é”®è¯æ’è¡Œ")
                for i, (word, count) in enumerate(results['keywords'][:15], 1):
                    percentage = round(count / results['total_comments'] * 100, 1) if results['total_comments'] > 0 else 0
                    st.markdown(f"""
                    <div style="display: flex; justify-content: space-between; padding: 0.2rem 0; border-bottom: 1px solid #eee;">
                        <span><strong>{i}. {word}</strong></span>
                        <span style="color: #666;">{count}æ¬¡ ({percentage}%)</span>
                    </div>
                    """, unsafe_allow_html=True)

        # AIæ´å¯Ÿå’Œå»ºè®®
        st.markdown("### ğŸ¤– AIæ™ºèƒ½æ´å¯Ÿ")
        
        insights = results['ai_insights']
        
        # ä¼˜å…ˆçº§é—®é¢˜
        if insights['priority_issues']:
            st.markdown("#### âš ï¸ ä¼˜å…ˆå¤„ç†é—®é¢˜")
            for issue in insights['priority_issues']:
                severity_color = {'é«˜': '#dc3545', 'ä¸­': '#ffc107', 'ä½': '#28a745'}
                st.markdown(f"""
                <div style="background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%); 
                           padding: 1rem; border-radius: 0.5rem; border-left: 4px solid {severity_color[issue['severity']]}; margin: 0.5rem 0;">
                    <strong>ğŸš¨ {issue['type']} (ä¼˜å…ˆçº§: {issue['severity']})</strong><br>
                    ğŸ“Š å½±å“èŒƒå›´: {issue['count']}æ¡è¯„è®º<br>
                    ğŸ’¡ {issue['description']}
                </div>
                """, unsafe_allow_html=True)
        
        # æ ¸å¿ƒè§‚ç‚¹å±•ç¤º
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ğŸ˜Š æ­£é¢åé¦ˆç²¾é€‰")
            for i, comment in enumerate(insights['positive_highlights'], 1):
                st.markdown(f"""
                <div class="insight-box positive-insight">
                    <strong>ğŸ’š ç”¨æˆ·å¥½è¯„ #{i}</strong><br>
                    "{comment}"
                </div>
                """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("#### ğŸ˜Ÿ è´Ÿé¢åé¦ˆç²¾é€‰")
            for i, comment in enumerate(insights['negative_highlights'], 1):
                st.markdown(f"""
                <div class="insight-box negative-insight">
                    <strong>ğŸ’” ç”¨æˆ·å·®è¯„ #{i}</strong><br>
                    "{comment}"
                </div>
                """, unsafe_allow_html=True)
        
        # AIå»ºè®®
        if insights['suggestions']:
            st.markdown("#### ğŸ’¡ AIæ”¹è¿›å»ºè®®")
            for i, suggestion in enumerate(insights['suggestions'], 1):
                st.markdown(f"**{i}.** {suggestion}")
        
        # å…³é”®è¯æ´å¯Ÿ
        keyword_insights = insights['keyword_insights']
        if keyword_insights['tech_focus'] or keyword_insights['ux_focus']:
            st.markdown("#### ğŸ” å…³é”®è¯æ´å¯Ÿ")
            if keyword_insights['tech_focus']:
                st.warning("âš™ï¸ æŠ€æœ¯é—®é¢˜å…³æ³¨åº¦è¾ƒé«˜ï¼Œå»ºè®®ä¼˜å…ˆå¤„ç†æŠ€æœ¯å±‚é¢çš„bugå’Œæ€§èƒ½é—®é¢˜")
            if keyword_insights['ux_focus']:
                st.info("ğŸ¨ ç”¨æˆ·ä½“éªŒè®¨è®ºè¾ƒå¤šï¼Œå»ºè®®å…³æ³¨ç•Œé¢è®¾è®¡å’Œäº¤äº’ä¼˜åŒ–")
        
        # å¯¼å‡ºåŠŸèƒ½
        st.markdown("---")
        st.markdown("### ğŸ“ åˆ†ææŠ¥å‘Šå¯¼å‡º")
        
        # ç”Ÿæˆå®Œæ•´æŠ¥å‘Šæ•°æ®
        complete_report = {
            "åˆ†ææ¦‚è¦": {
                "åˆ†ææ—¶é—´": results['analysis_time'],
                "æ€»è¯„è®ºæ•°": results['total_comments'],
                "åˆ†æç½®ä¿¡åº¦": f"{round(results['avg_confidence'] * 100, 1)}%"
            },
            "æƒ…æ„Ÿåˆ†æç»“æœ": results['sentiment_results'],
            "æ„å›¾åˆ†ç±»ç»“æœ": results['intent_results'],
            "å…³é”®è¯åˆ†æ": {
                "é«˜é¢‘è¯æ±‡": dict(results['keywords'][:20])
            },
            "AIæ´å¯Ÿ": {
                "ä¼˜å…ˆé—®é¢˜": insights['priority_issues'],
                "æ”¹è¿›å»ºè®®": insights['suggestions'],
                "å…³é”®è¯æ´å¯Ÿ": insights['keyword_insights']
            },
            "ä»£è¡¨æ€§è¯„è®º": {
                "æ­£é¢åé¦ˆ": insights['positive_highlights'],
                "è´Ÿé¢åé¦ˆ": insights['negative_highlights']
            }
        }
        
        # ç”Ÿæˆè¯¦ç»†çš„CSVæ•°æ®
        detailed_data = []
        for detail in results['sentiment_details']:
            intent_info = next((item for item in results['intent_details'] 
                              if item['comment'] == detail['comment']), {'intent': 'æœªåˆ†ç±»'})
            detailed_data.append({
                'è¯„è®ºå†…å®¹': detail['comment'],
                'æƒ…æ„Ÿå€¾å‘': detail['sentiment'],
                'æƒ…æ„Ÿç½®ä¿¡åº¦': round(detail['confidence'], 3),
                'æ„å›¾åˆ†ç±»': intent_info['intent'],
                'æ­£é¢å¾—åˆ†': detail['pos_score'],
                'è´Ÿé¢å¾—åˆ†': detail['neg_score']
            })
        
        df_detailed = pd.DataFrame(detailed_data)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # JSONæŠ¥å‘Šä¸‹è½½
            report_json = json.dumps(complete_report, ensure_ascii=False, indent=2)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½JSONåˆ†ææŠ¥å‘Š",
                data=report_json,
                file_name=f"echo_ai_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                use_container_width=True
            )
        
        with col2:
            # CSVè¯¦ç»†æ•°æ®ä¸‹è½½
            csv_data = df_detailed.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“Š ä¸‹è½½CSVè¯¦ç»†æ•°æ®",
                data=csv_data,
                file_name=f"echo_detailed_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        with col3:
            # ç”Ÿæˆç®€è¦æ€»ç»“æŠ¥å‘Š
            summary_report = f"""
Echo AIåˆ†ææŠ¥å‘Šæ‘˜è¦
===================
åˆ†ææ—¶é—´: {results['analysis_time']}
æ€»è¯„è®ºæ•°: {results['total_comments']}æ¡
åˆ†æç½®ä¿¡åº¦: {round(results['avg_confidence'] * 100, 1)}%

æƒ…æ„Ÿåˆ†å¸ƒ:
â€¢ æ­£é¢è¯„ä»·: {results['sentiment_results']['positive']}æ¡ ({round(results['sentiment_results']['positive']/results['total_comments']*100, 1)}%)
â€¢ è´Ÿé¢è¯„ä»·: {results['sentiment_results']['negative']}æ¡ ({round(results['sentiment_results']['negative']/results['total_comments']*100, 1)}%)
â€¢ ä¸­æ€§è¯„ä»·: {results['sentiment_results']['neutral']}æ¡ ({round(results['sentiment_results']['neutral']/results['total_comments']*100, 1)}%)

ä¸»è¦åé¦ˆç±»å‹:
{chr(10).join([f"â€¢ {k}: {v}æ¡" for k, v in results['intent_results'].items() if v > 0])}

é«˜é¢‘å…³é”®è¯:
{', '.join([word for word, count in results['keywords'][:10]])}

ä¸»è¦å»ºè®®:
{chr(10).join([f"â€¢ {suggestion}" for suggestion in insights['suggestions']])}
            """
            
            st.download_button(
                label="ğŸ“„ ä¸‹è½½æ‘˜è¦æŠ¥å‘Š",
                data=summary_report,
                file_name=f"echo_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain",
                use_container_width=True
            )
        
        # æ•°æ®è¡¨æ ¼å±•ç¤º
        st.markdown("### ğŸ“‹ è¯¦ç»†æ•°æ®è¡¨æ ¼")
        
        # æ•°æ®ç­›é€‰å™¨
        col1, col2, col3 = st.columns(3)
        with col1:
            sentiment_filter = st.multiselect(
                "ç­›é€‰æƒ…æ„Ÿç±»å‹:",
                ['positive', 'negative', 'neutral'],
                default=['positive', 'negative', 'neutral'],
                format_func=lambda x: {'positive': 'æ­£é¢', 'negative': 'è´Ÿé¢', 'neutral': 'ä¸­æ€§'}[x]
            )
        
        with col2:
            intent_options = list(set([item['intent'] for item in results['intent_details']]))
            intent_filter = st.multiselect(
                "ç­›é€‰æ„å›¾ç±»å‹:",
                intent_options,
                default=intent_options
            )
        
        with col3:
            confidence_min = st.slider("æœ€ä½ç½®ä¿¡åº¦:", 0.0, 1.0, 0.0, 0.1)
        
        # åº”ç”¨ç­›é€‰å™¨
        filtered_df = df_detailed[
            (df_detailed['æƒ…æ„Ÿå€¾å‘'].isin(sentiment_filter)) &
            (df_detailed['æ„å›¾åˆ†ç±»'].isin(intent_filter)) &
            (df_detailed['æƒ…æ„Ÿç½®ä¿¡åº¦'] >= confidence_min)
        ]
        
        st.dataframe(
            filtered_df,
            use_container_width=True,
            height=400,
            column_config={
                "è¯„è®ºå†…å®¹": st.column_config.TextColumn("è¯„è®ºå†…å®¹", width="large"),
                "æƒ…æ„Ÿå€¾å‘": st.column_config.TextColumn("æƒ…æ„Ÿå€¾å‘", width="small"),
                "æƒ…æ„Ÿç½®ä¿¡åº¦": st.column_config.ProgressColumn("ç½®ä¿¡åº¦", min_value=0, max_value=1),
                "æ„å›¾åˆ†ç±»": st.column_config.TextColumn("æ„å›¾åˆ†ç±»", width="medium"),
                "æ­£é¢å¾—åˆ†": st.column_config.NumberColumn("æ­£é¢å¾—åˆ†", format="%d"),
                "è´Ÿé¢å¾—åˆ†": st.column_config.NumberColumn("è´Ÿé¢å¾—åˆ†", format="%d")
            }
        )
        
        st.markdown(f"ğŸ“Š æ˜¾ç¤º {len(filtered_df)} / {len(df_detailed)} æ¡è®°å½•")
        
        # é«˜çº§åˆ†æåŠŸèƒ½
        st.markdown("---")
        st.markdown("### ğŸ”¬ é«˜çº§åˆ†æåŠŸèƒ½")
        
        tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ è¶‹åŠ¿åˆ†æ", "ğŸ”— å…³è”åˆ†æ", "ğŸ¯ åˆ†ç¾¤åˆ†æ"])
        
        with tab1:
            st.markdown("#### æƒ…æ„Ÿè¶‹åŠ¿åˆ†æ")
            
            # æŒ‰è¯„è®ºé•¿åº¦åˆ†ææƒ…æ„Ÿåˆ†å¸ƒ
            df_detailed['è¯„è®ºé•¿åº¦'] = df_detailed['è¯„è®ºå†…å®¹'].str.len()
            length_bins = pd.cut(df_detailed['è¯„è®ºé•¿åº¦'], bins=5, labels=['å¾ˆçŸ­', 'è¾ƒçŸ­', 'ä¸­ç­‰', 'è¾ƒé•¿', 'å¾ˆé•¿'])
            df_detailed['é•¿åº¦åˆ†ç»„'] = length_bins
            
            length_sentiment = df_detailed.groupby(['é•¿åº¦åˆ†ç»„', 'æƒ…æ„Ÿå€¾å‘']).size().unstack(fill_value=0)
            all_sentiment_columns = ['positive', 'negative', 'neutral']
# 2. ä½¿ç”¨ reindex æ–¹æ³•ï¼Œè¡¥å…¨ç¼ºå¤±çš„åˆ—ï¼Œå¹¶ç”¨ 0 å¡«å……
            length_sentiment = length_sentiment.reindex(columns=all_sentiment_columns, fill_value=0)
            
            fig_trend = px.bar(
                x=length_sentiment.index,
                y=[length_sentiment['positive'], length_sentiment['negative'], length_sentiment['neutral']],
                title="ä¸åŒè¯„è®ºé•¿åº¦çš„æƒ…æ„Ÿåˆ†å¸ƒ",
                labels={'x': 'è¯„è®ºé•¿åº¦åˆ†ç»„', 'y': 'è¯„è®ºæ•°é‡'},
                color_discrete_map={'positive': '#28a745', 'negative': '#dc3545', 'neutral': '#ffc107'}
            )
            
            st.plotly_chart(fig_trend, use_container_width=True)
        
        with tab2:
            st.markdown("#### å…³é”®è¯å…³è”åˆ†æ")
            
            # åˆ†æå…³é”®è¯ä¸æƒ…æ„Ÿçš„å…³è”
            keyword_sentiment = {}
            for detail in results['sentiment_details']:
                comment = detail['comment'].lower()
                sentiment = detail['sentiment']
                
                for word, count in results['keywords'][:15]:
                    if word.lower() in comment:
                        if word not in keyword_sentiment:
                            keyword_sentiment[word] = {'positive': 0, 'negative': 0, 'neutral': 0}
                        keyword_sentiment[word][sentiment] += 1
            
            # åˆ›å»ºå…³è”çƒ­åŠ›å›¾æ•°æ®
            heatmap_data = []
            for word, sentiments in keyword_sentiment.items():
                total = sum(sentiments.values())
                if total > 0:
                    heatmap_data.append({
                        'å…³é”®è¯': word,
                        'æ­£é¢å…³è”åº¦': sentiments['positive'] / total,
                        'è´Ÿé¢å…³è”åº¦': sentiments['negative'] / total,
                        'ä¸­æ€§å…³è”åº¦': sentiments['neutral'] / total,
                        'æ€»å‡ºç°æ¬¡æ•°': total
                    })
            
            if heatmap_data:
                df_heatmap = pd.DataFrame(heatmap_data)
                df_heatmap = df_heatmap.sort_values('æ€»å‡ºç°æ¬¡æ•°', ascending=False).head(10)
                
                fig_heatmap = px.imshow(
                    df_heatmap[['æ­£é¢å…³è”åº¦', 'ä¸­æ€§å…³è”åº¦', 'è´Ÿé¢å…³è”åº¦']].T,
                    x=df_heatmap['å…³é”®è¯'],
                    y=['æ­£é¢å…³è”åº¦', 'ä¸­æ€§å…³è”åº¦', 'è´Ÿé¢å…³è”åº¦'],
                    color_continuous_scale='RdYlBu_r',
                    title="å…³é”®è¯æƒ…æ„Ÿå…³è”çƒ­åŠ›å›¾"
                )
                
                st.plotly_chart(fig_heatmap, use_container_width=True)
        
        with tab3:
            st.markdown("#### ç”¨æˆ·åˆ†ç¾¤åˆ†æ")
            
            # åŸºäºæƒ…æ„Ÿå’Œæ„å›¾è¿›è¡Œç”¨æˆ·åˆ†ç¾¤
            cluster_data = df_detailed.groupby(['æƒ…æ„Ÿå€¾å‘', 'æ„å›¾åˆ†ç±»']).size().reset_index(name='æ•°é‡')
            
            fig_cluster = px.sunburst(
                cluster_data,
                path=['æƒ…æ„Ÿå€¾å‘', 'æ„å›¾åˆ†ç±»'],
                values='æ•°é‡',
                title="ç”¨æˆ·åé¦ˆåˆ†ç¾¤æ—­æ—¥å›¾",
                color='æ•°é‡',
                color_continuous_scale='viridis'
            )
            
            st.plotly_chart(fig_cluster, use_container_width=True)
            
            # åˆ†ç¾¤ç‰¹å¾æè¿°
            st.markdown("##### ğŸ¯ åˆ†ç¾¤ç‰¹å¾åˆ†æ")
            
            major_clusters = cluster_data.nlargest(3, 'æ•°é‡')
            for idx, cluster in major_clusters.iterrows():
                st.markdown(f"""
                **ç¾¤ä½“ {idx+1}: {cluster['æƒ…æ„Ÿå€¾å‘']} + {cluster['æ„å›¾åˆ†ç±»']}**
                - è§„æ¨¡: {cluster['æ•°é‡']}æ¡è¯„è®º ({round(cluster['æ•°é‡']/results['total_comments']*100, 1)}%)
                - ç‰¹å¾: {'ç§¯æç”¨æˆ·ï¼Œå¯¹äº§å“ä½“éªŒæ»¡æ„' if cluster['æƒ…æ„Ÿå€¾å‘'] == 'positive' else 'æœ‰å¾…æ”¹å–„çš„ç”¨æˆ·ä½“éªŒ' if cluster['æƒ…æ„Ÿå€¾å‘'] == 'negative' else 'ä¸­æ€§ç”¨æˆ·ç¾¤ä½“'}
                """)

    # æ¯”è¾ƒåˆ†æåŠŸèƒ½
    if st.session_state.analysis_count > 1:
        st.markdown("---")
        st.markdown("### ğŸ“Š å†å²å¯¹æ¯”åˆ†æ")
        st.info("ğŸ’¡ å¤šæ¬¡åˆ†æåå¯ä»¥æŸ¥çœ‹è¶‹åŠ¿å˜åŒ–ï¼ˆåŠŸèƒ½è§„åˆ’ä¸­ï¼‰")

    # é¡µé¢åº•éƒ¨
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                color: white; padding: 2rem; border-radius: 1rem; margin: 2rem 0;'>
        <h3>ğŸš€ ç”¨æˆ·ä¹‹å£°å›éŸ³å£ (Echo) Pro</h3>
        <p style='margin: 0; font-size: 1.1rem;'>AIèµ‹èƒ½çš„ç”¨æˆ·åé¦ˆæ™ºèƒ½åˆ†æå¹³å° | è®©æ¯ä¸ªå£°éŸ³éƒ½è¢«å¬è§ã€è¢«ç†è§£ã€è¢«åˆ†æ</p>
        <small>Powered by Advanced AI Technology</small>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()